---
title: "Konvertierung ntsworkflow RDS in JSON"
author: "K Jewell"
date: "5/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Einleitung

Die Angefragte Leistung umfasst die Erstellung eines R-Skripts zur Konvertierung von `data.frame`s (.RDS Datei) und Messdaten (.mzXML) in einen json formatierten Text Datei für das Ingest in ElasticSearch. 

Der Skript sollte ähnlich wie `dbas3.R` funktionieren aber für ein anderes Input-Format. Sowie `dbas3.R`, bekommt den zu erstellenden Skript eine .yaml Datei (und csv Dateien) mit Metadaten und annotiert damit die Dokumente bei der Umformatierung.

## Leistungsbeschreibung detailliert

### Stuktur des json Dokuments

```{json}
{
  "mappings" : {
    "properties" : {
      "ufid" : {"type" : "long"},
      "area" : {"type" : "float"},
      "area_is" : {"type" : "float"},
      "intensity" : {"type" : "float"},
      "intensity_is" : {"type" : "float"},
      "cas" : {"type" : "keyword"},
      "comment" : {"type" : "text"},
      "tag": {"type": "keyword"},
      "data_source" : {"type" : "keyword"},
      "start" : {
        "type" : "date",
        "format" : "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd"
      },
      "km": { "type" : "float" },
      "gkz" : { "type" : "integer" },
      "river" : { "type" : "keyword" },
      "duration" : {"type" : "float"},
      "date_import" : {
        "type" : "date",
        "format" : "epoch_second"
      },
      "eic" : {
        "type" : "nested",
        "properties" : {
          "int" : {
            "type" : "float"
          },
          "time" : {
            "type" : "short"
          }
        }
      },
      "hplc_method" : {"type" : "keyword"},
      "loc" : {"type" : "geo_point"},
      "matrix" : {"type" : "keyword"},
      "ms1" : {                           
        "type" : "nested",                
        "properties" : {
          "int" : {
            "type" : "float"
          },
          "mz" : {
            "type" : "float"
          }
        }
      },
      "ms2" : {
        "type" : "nested",
        "properties" : {
          "int" : {
            "type" : "float"
          },
          "mz" : {
            "type" : "float"
          }
        }
      },
      "mz" : {"type" : "float"},
      "name" : {"type" : "keyword"},
      "norm_a" : {"type" : "float"},
      "pol" : {"type" : "keyword"},
      "rt" : {"type" : "float"},
      "rtt" : {
        "type" : "nested",
        "properties" : {
          "method" : {
            "type" : "keyword"
          },
          "predicted" : {
            "type" : "boolean"
          },
          "rt" : {
            "type" : "float"
          }
        }
      },
      "filename" : {"type" : "keyword"},
      "station" : {"type" : "keyword"}
    }
  }
}
```

#### Beispiel eines Dokuments

Siehe `example_doc.json`.

#### Beispiel dbas3.R

dbas3.R konvertiert Daten vom .report Format zu json format. .report ist nur eine Name, die wir definiert haben, eigentlich ist das ein RC Objekt gespeichert als RDS Datei. Alle notwendigen Informationen für die Bildung von jsons sind in der .report Datei (z.B. `saale_pos2_i.report`) vorhanden bzw. in der Settings Datei (z.B. `dbas_settings_saale.yaml`).

```{r}
example <- readRDS("saale_pos2_i.report")
```

```{r, eval=FALSE}
example$view()  # shiny Fenster zur Visualisierung
```


```{r}
head(example$ISresults)
```


```{r}
head(example$integRes)
```

```{r}
head(example$EIC)
```

```{r}
head(example$MS1)
```

```{r}
head(example$MS2)
```

Die Tabelle example$integRes bildet die Basis, jede Zeile wird ein Dokument (dbas3.R Zeile 51), zu diesen Daten (variable `dat`) werden die anderen notwendigen Informationen hinzugeschrieben.

Der neue Skript funktioniert auf eine ähnliche Art nur er bekommt anders formatierte Daten. Als Argument a) eine .RDS Datei (Struktur wird unten beschrieben), die anders strukturiert ist als *.report. b) eine Settingsdatei wie `dbas_settings_saale.yaml`. Output: json Datei wie saale_pos2_i.json


### Struktur der RDS Datei



```{r}
ntsDat <- readRDS("rhine_example_eval.RDS")
```

```{r}
head(ntsDat$grouped)
```
Hier, mz_X, RT_X und Int_X bilden die Basis für jedes Dokument. Im folgenden wird aufgelistet, wo sich alle notwendigen Daten befinden.

#### mz
```{r}
head(ntsDat$grouped[, grep("mz_", colnames(ntsDat$grouped))])
```

#### rt
```{r}
head(ntsDat$grouped[, grep("RT_", colnames(ntsDat$grouped))])
```

#### intensity
```{r}
head(ntsDat$grouped[, grep("Int_", colnames(ntsDat$grouped))])
```

#### intensity_is
```{r, eval=FALSE}
head(ntsDat$grouped[Zeile, grep("Int_", colnames(ntsDat$grouped))])
```
Ziele muss bestimmt werden (Eingrenzung mz_ und RT_)

#### area
```{r}
head(ntsDat$grouped[, grep("PeakID", colnames(ntsDat$grouped))])
ntsDat$peaklist[[1]]$peak_id_all
ntsDat$peaklist[[1]]$Area
```
#### area_is
siehe intensity_is

#### start
Von Dateiname (regex) oder settings Datei => csv

#### eic


#### ms1


#### ms2


#### filename

```{r}
ntsDat$sampleList
```


#### andere

Von Settings Datei
comment, tag, data_source, pol,  matrix, duration, station,

Von csv (pfad in der Settings Datei)
gkz, loc, km, river





